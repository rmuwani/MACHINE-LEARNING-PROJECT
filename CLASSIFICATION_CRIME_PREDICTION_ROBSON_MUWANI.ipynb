{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from math import sqrt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('crime_data_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(n=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFENSE_CODE_GROUP</th>\n",
       "      <th>DISTRICT</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>UCR_PART</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4513</td>\n",
       "      <td>Aggravated Assault</td>\n",
       "      <td>D4</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Monday</td>\n",
       "      <td>21</td>\n",
       "      <td>Part One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9359</td>\n",
       "      <td>Motor Vehicle Accident Response</td>\n",
       "      <td>B2</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>42.339623</td>\n",
       "      <td>-71.106497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131144</td>\n",
       "      <td>Auto Theft</td>\n",
       "      <td>B3</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>15</td>\n",
       "      <td>Part One</td>\n",
       "      <td>42.290425</td>\n",
       "      <td>-71.090491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41458</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>B3</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>42.281625</td>\n",
       "      <td>-71.083192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258315</td>\n",
       "      <td>Motor Vehicle Accident Response</td>\n",
       "      <td>B2</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>19</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>42.330206</td>\n",
       "      <td>-71.083178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     OFFENSE_CODE_GROUP DISTRICT  YEAR  MONTH DAY_OF_WEEK  \\\n",
       "4513                 Aggravated Assault       D4  2018      9      Monday   \n",
       "9359    Motor Vehicle Accident Response       B2  2018      8     Tuesday   \n",
       "131144                       Auto Theft       B3  2017      6    Thursday   \n",
       "41458                             Fraud       B3  2018      5      Friday   \n",
       "258315  Motor Vehicle Accident Response       B2  2016      3      Sunday   \n",
       "\n",
       "        HOUR    UCR_PART        Lat       Long  \n",
       "4513      21    Part One        NaN        NaN  \n",
       "9359      12  Part Three  42.339623 -71.106497  \n",
       "131144    15    Part One  42.290425 -71.090491  \n",
       "41458      1    Part Two  42.281625 -71.083192  \n",
       "258315    19  Part Three  42.330206 -71.083178  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df,columns=['OFFENSE_CODE_GROUP','DISTRICT',\n",
    "                                      'DAY_OF_WEEK',],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>UCR_PART</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Aircraft</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Arson</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Assembly or Gathering Violations</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Auto Theft</th>\n",
       "      <th>...</th>\n",
       "      <th>DISTRICT_D4</th>\n",
       "      <th>DISTRICT_E13</th>\n",
       "      <th>DISTRICT_E18</th>\n",
       "      <th>DISTRICT_E5</th>\n",
       "      <th>DAY_OF_WEEK_Monday</th>\n",
       "      <th>DAY_OF_WEEK_Saturday</th>\n",
       "      <th>DAY_OF_WEEK_Sunday</th>\n",
       "      <th>DAY_OF_WEEK_Thursday</th>\n",
       "      <th>DAY_OF_WEEK_Tuesday</th>\n",
       "      <th>DAY_OF_WEEK_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4513</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>Part One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9359</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>42.339623</td>\n",
       "      <td>-71.106497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131144</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>Part One</td>\n",
       "      <td>42.290425</td>\n",
       "      <td>-71.090491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41458</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Part Two</td>\n",
       "      <td>42.281625</td>\n",
       "      <td>-71.083192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258315</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>Part Three</td>\n",
       "      <td>42.330206</td>\n",
       "      <td>-71.083178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  HOUR    UCR_PART        Lat       Long  \\\n",
       "4513    2018      9    21    Part One        NaN        NaN   \n",
       "9359    2018      8    12  Part Three  42.339623 -71.106497   \n",
       "131144  2017      6    15    Part One  42.290425 -71.090491   \n",
       "41458   2018      5     1    Part Two  42.281625 -71.083192   \n",
       "258315  2016      3    19  Part Three  42.330206 -71.083178   \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Aircraft  OFFENSE_CODE_GROUP_Arson  \\\n",
       "4513                              0                         0   \n",
       "9359                              0                         0   \n",
       "131144                            0                         0   \n",
       "41458                             0                         0   \n",
       "258315                            0                         0   \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Assembly or Gathering Violations  \\\n",
       "4513                                                    0     \n",
       "9359                                                    0     \n",
       "131144                                                  0     \n",
       "41458                                                   0     \n",
       "258315                                                  0     \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Auto Theft  ...  DISTRICT_D4  DISTRICT_E13  \\\n",
       "4513                                0  ...            1             0   \n",
       "9359                                0  ...            0             0   \n",
       "131144                              1  ...            0             0   \n",
       "41458                               0  ...            0             0   \n",
       "258315                              0  ...            0             0   \n",
       "\n",
       "        DISTRICT_E18  DISTRICT_E5  DAY_OF_WEEK_Monday  DAY_OF_WEEK_Saturday  \\\n",
       "4513               0            0                   1                     0   \n",
       "9359               0            0                   0                     0   \n",
       "131144             0            0                   0                     0   \n",
       "41458              0            0                   0                     0   \n",
       "258315             0            0                   0                     0   \n",
       "\n",
       "        DAY_OF_WEEK_Sunday  DAY_OF_WEEK_Thursday  DAY_OF_WEEK_Tuesday  \\\n",
       "4513                     0                     0                    0   \n",
       "9359                     0                     0                    1   \n",
       "131144                   0                     1                    0   \n",
       "41458                    0                     0                    0   \n",
       "258315                   1                     0                    0   \n",
       "\n",
       "        DAY_OF_WEEK_Wednesday  \n",
       "4513                        0  \n",
       "9359                        0  \n",
       "131144                      0  \n",
       "41458                       0  \n",
       "258315                      0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy.UCR_PART = df_dummy.UCR_PART.map({\n",
    "                                \n",
    "                                'Part Three':1,\n",
    "                                'Part Two':2,\n",
    "                                'Part One':3                                                       \n",
    "                                                                \n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>UCR_PART</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Aircraft</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Arson</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Assembly or Gathering Violations</th>\n",
       "      <th>OFFENSE_CODE_GROUP_Auto Theft</th>\n",
       "      <th>...</th>\n",
       "      <th>DISTRICT_D4</th>\n",
       "      <th>DISTRICT_E13</th>\n",
       "      <th>DISTRICT_E18</th>\n",
       "      <th>DISTRICT_E5</th>\n",
       "      <th>DAY_OF_WEEK_Monday</th>\n",
       "      <th>DAY_OF_WEEK_Saturday</th>\n",
       "      <th>DAY_OF_WEEK_Sunday</th>\n",
       "      <th>DAY_OF_WEEK_Thursday</th>\n",
       "      <th>DAY_OF_WEEK_Tuesday</th>\n",
       "      <th>DAY_OF_WEEK_Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4513</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9359</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.339623</td>\n",
       "      <td>-71.106497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131144</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.290425</td>\n",
       "      <td>-71.090491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41458</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.281625</td>\n",
       "      <td>-71.083192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258315</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.330206</td>\n",
       "      <td>-71.083178</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  HOUR  UCR_PART        Lat       Long  \\\n",
       "4513    2018      9    21       3.0        NaN        NaN   \n",
       "9359    2018      8    12       1.0  42.339623 -71.106497   \n",
       "131144  2017      6    15       3.0  42.290425 -71.090491   \n",
       "41458   2018      5     1       2.0  42.281625 -71.083192   \n",
       "258315  2016      3    19       1.0  42.330206 -71.083178   \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Aircraft  OFFENSE_CODE_GROUP_Arson  \\\n",
       "4513                              0                         0   \n",
       "9359                              0                         0   \n",
       "131144                            0                         0   \n",
       "41458                             0                         0   \n",
       "258315                            0                         0   \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Assembly or Gathering Violations  \\\n",
       "4513                                                    0     \n",
       "9359                                                    0     \n",
       "131144                                                  0     \n",
       "41458                                                   0     \n",
       "258315                                                  0     \n",
       "\n",
       "        OFFENSE_CODE_GROUP_Auto Theft  ...  DISTRICT_D4  DISTRICT_E13  \\\n",
       "4513                                0  ...            1             0   \n",
       "9359                                0  ...            0             0   \n",
       "131144                              1  ...            0             0   \n",
       "41458                               0  ...            0             0   \n",
       "258315                              0  ...            0             0   \n",
       "\n",
       "        DISTRICT_E18  DISTRICT_E5  DAY_OF_WEEK_Monday  DAY_OF_WEEK_Saturday  \\\n",
       "4513               0            0                   1                     0   \n",
       "9359               0            0                   0                     0   \n",
       "131144             0            0                   0                     0   \n",
       "41458              0            0                   0                     0   \n",
       "258315             0            0                   0                     0   \n",
       "\n",
       "        DAY_OF_WEEK_Sunday  DAY_OF_WEEK_Thursday  DAY_OF_WEEK_Tuesday  \\\n",
       "4513                     0                     0                    0   \n",
       "9359                     0                     0                    1   \n",
       "131144                   0                     1                    0   \n",
       "41458                    0                     0                    0   \n",
       "258315                   1                     0                    0   \n",
       "\n",
       "        DAY_OF_WEEK_Wednesday  \n",
       "4513                        0  \n",
       "9359                        0  \n",
       "131144                      0  \n",
       "41458                       0  \n",
       "258315                      0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                       int64\n",
       "MONTH                      int64\n",
       "HOUR                       int64\n",
       "UCR_PART                 float64\n",
       "Lat                      float64\n",
       "                          ...   \n",
       "DAY_OF_WEEK_Saturday       uint8\n",
       "DAY_OF_WEEK_Sunday         uint8\n",
       "DAY_OF_WEEK_Thursday       uint8\n",
       "DAY_OF_WEEK_Tuesday        uint8\n",
       "DAY_OF_WEEK_Wednesday      uint8\n",
       "Length: 82, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                       0\n",
       "MONTH                      0\n",
       "HOUR                       0\n",
       "UCR_PART                  69\n",
       "Lat                      977\n",
       "                        ... \n",
       "DAY_OF_WEEK_Saturday       0\n",
       "DAY_OF_WEEK_Sunday         0\n",
       "DAY_OF_WEEK_Thursday       0\n",
       "DAY_OF_WEEK_Tuesday        0\n",
       "DAY_OF_WEEK_Wednesday      0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                     0\n",
       "MONTH                    0\n",
       "HOUR                     0\n",
       "UCR_PART                 0\n",
       "Lat                      0\n",
       "                        ..\n",
       "DAY_OF_WEEK_Saturday     0\n",
       "DAY_OF_WEEK_Sunday       0\n",
       "DAY_OF_WEEK_Thursday     0\n",
       "DAY_OF_WEEK_Tuesday      0\n",
       "DAY_OF_WEEK_Wednesday    0\n",
       "Length: 82, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                       int64\n",
       "MONTH                      int64\n",
       "HOUR                       int64\n",
       "UCR_PART                 float64\n",
       "Lat                      float64\n",
       "                          ...   \n",
       "DAY_OF_WEEK_Saturday       uint8\n",
       "DAY_OF_WEEK_Sunday         uint8\n",
       "DAY_OF_WEEK_Thursday       uint8\n",
       "DAY_OF_WEEK_Tuesday        uint8\n",
       "DAY_OF_WEEK_Wednesday      uint8\n",
       "Length: 82, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dfs.columns[dfs.dtypes.eq('object')]\n",
    "dfs[cols] = dfs[cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfs.drop('UCR_PART',axis=1)\n",
    "y=dfs['UCR_PART']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning -GridsearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "#solver_options = ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "#solver_options = [ 'liblinear', 'sag']\n",
    "solver_options = [ 'liblinear']\n",
    "#penalty_options=['l1', 'l2', 'elasticnet', 'none']\n",
    "penalty_options=['l1', 'l2']\n",
    "#multi_class_options = ['ovr', 'multinomial','auto']\n",
    "multi_class_options = ['ovr','auto']\n",
    "#class_weight_options = ['None', 'balanced']\n",
    "class_weight_options = ['balanced']\n",
    "param_grid = dict(solver = solver_options, multi_class =\n",
    "                  multi_class_options, class_weight = class_weight_options,penalty=penalty_options)\n",
    "\n",
    "grid = GridSearchCV(lr, param_grid, cv=5, scoring = \n",
    "'accuracy')\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "grid.best_params_\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced',\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9958989031950405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012717771445853905"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get k fold stdv\n",
    "grid.cv_results_['std_test_score'][grid.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.99      1.00      1720\n",
      "         2.0       0.99      1.00      0.99      1080\n",
      "         3.0       1.00      1.00      1.00       697\n",
      "\n",
      "    accuracy                           1.00      3497\n",
      "   macro avg       1.00      1.00      1.00      3497\n",
      "weighted avg       1.00      1.00      1.00      3497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make prediction\n",
    "clf = LogisticRegression(class_weight='balanced',multi_class='ovr',penalty='l1',solver='liblinear',random_state = 0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred_clf=clf.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred_clf)\n",
    "confusion_matrix(y_test,y_pred_clf)\n",
    "print(classification_report(y_test,y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996568487274807"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN-CLASSIFICATION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfs.drop('UCR_PART',axis=1)\n",
    "y=dfs['UCR_PART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_scaled = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939935645334287"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning using Gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "reg=KNeighborsClassifier()\n",
    "param_dict = {\n",
    "                'n_neighbors': [3,5],\n",
    "                'weights' : ['uniform','distance'],\n",
    "                'metric' : ['euclidean', 'manhattan']\n",
    "                              \n",
    "            }\n",
    "clf = GridSearchCV(reg,param_dict,cv=5)\n",
    "clf.fit(X_scaled,y)\n",
    "clf.best_params_\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008896289803607617"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get k fold stdv\n",
    "clf.cv_results_['std_test_score'][clf.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3, weights='uniform', metric='euclidean')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1708   10    2]\n",
      " [   2 1078    0]\n",
      " [   4    0  693]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.99      0.99      1720\n",
      "         2.0       0.99      1.00      0.99      1080\n",
      "         3.0       1.00      0.99      1.00       697\n",
      "\n",
      "    accuracy                           0.99      3497\n",
      "   macro avg       0.99      1.00      0.99      3497\n",
      "weighted avg       0.99      0.99      0.99      3497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfs.drop('UCR_PART',axis=1)\n",
    "y=dfs['UCR_PART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 42.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 57.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9696926273554489"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning using Gridsearch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_dict = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(rf,param_dict,cv=5,n_jobs = -1, verbose = 2)\n",
    "clf.fit(X,y)\n",
    "clf.best_params_\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 80,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696926273554489"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0028526981066457993"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get k fold stdv\n",
    "clf.cv_results_['std_test_score'][clf.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=80, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=3, min_samples_split=8,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(bootstrap=True,max_depth=80,max_features=3,min_samples_leaf=3,\n",
    "                            min_samples_split=8,n_estimators=1000)\n",
    "                          \n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689067201604814"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3380   24    0]\n",
      " [  18 2150    0]\n",
      " [ 175    0 1232]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.99      0.97      3404\n",
      "         2.0       0.99      0.99      0.99      2168\n",
      "         3.0       1.00      0.88      0.93      1407\n",
      "\n",
      "    accuracy                           0.97      6979\n",
      "   macro avg       0.98      0.95      0.96      6979\n",
      "weighted avg       0.97      0.97      0.97      6979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfs.drop('UCR_PART',axis=1)\n",
    "y=dfs['UCR_PART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "sc_X = StandardScaler()\n",
    "X_scaled = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957727305294835"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning using Gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "param_dict = {\n",
    "                'kernel': ['linear', 'poly', 'rbf'],\n",
    "                'degree' : [2,3],\n",
    "                'gamma' : [0.01, 0.1,1,10],\n",
    "                'C': [0.01, 0.1,1,10]                \n",
    "            }\n",
    "clf = GridSearchCV(SVC(),param_dict,cv=4)\n",
    "clf.fit(X_scaled,y)\n",
    "clf.best_params_\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'degree': 2, 'gamma': 0.01, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957727305294835"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010781271533125698"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get k fold stdv\n",
    "clf.cv_results_['std_test_score'][clf.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear',gamma=0.01,C=0.01)\n",
    "svm.fit(X_train_scaled,y_train)\n",
    "y_pred_svm=svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9664756446991404"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1695   11    0]\n",
      " [   2 1082    0]\n",
      " [   0    0  700]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "accuracy_score(y_test,y_pred_svm)\n",
    "print(confusion_matrix(y_test,y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.99      1.00      1706\n",
      "         2.0       0.99      1.00      0.99      1084\n",
      "         3.0       1.00      1.00      1.00       700\n",
      "\n",
      "    accuracy                           1.00      3490\n",
      "   macro avg       1.00      1.00      1.00      3490\n",
      "weighted avg       1.00      1.00      1.00      3490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION-ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dfs.drop('UCR_PART',axis=1)\n",
    "y=dfs['UCR_PART']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904476760764186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid={\n",
    "    'base_estimator':[DecisionTreeClassifier(max_depth=1),DecisionTreeClassifier(max_depth=5),\n",
    "                                             DecisionTreeClassifier(max_depth=10)],\n",
    "           'n_estimators':[10,20,30]\n",
    "           }\n",
    "ABC = AdaBoostClassifier()\n",
    "ada = GridSearchCV(ABC, param_grid, cv=5)\n",
    "ada.fit(X_train,y_train)\n",
    "ada.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                        max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort=False,\n",
       "                        random_state=None, splitter='best'),\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9914444602880365"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036050518153600275"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get k fold stdv\n",
    "ada.cv_results_['std_test_score'][ada.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9903051040775591"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5),n_estimators=30,random_state=0)\n",
    "adaboost.fit(X_train,y_train)\n",
    "adaboost.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = adaboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3360   28    3]\n",
      " [  28 2166    8]\n",
      " [   1    0 1420]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.99      0.99      0.99      3391\n",
      "         2.0       0.99      0.98      0.99      2202\n",
      "         3.0       0.99      1.00      1.00      1421\n",
      "\n",
      "    accuracy                           0.99      7014\n",
      "   macro avg       0.99      0.99      0.99      7014\n",
      "weighted avg       0.99      0.99      0.99      7014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
